export const questions =
[
    {
        "section": "Introduction to Computer Vision",
        "question": "Computer Vision is a multidisciplinary field that combines:",
        "options": [
            "Mathematics, Physics, and Medicine",
            "Computer Science, Mathematics, and Electrical Engineering",
            "Biology, Psychology, and Computer Science",
            "Statistics, Chemistry, and Computer Engineering"
        ],
        "answer": 1
    },
    {
        "section": "Objectives of Computer Vision",
        "question": "Which of the following is NOT an objective of computer vision?",
        "options": [
            "Recognizing patterns in images such as human faces",
            "Extracting quantitative measurements such as object counting",
            "Performing semantic understanding such as scene segmentation",
            "Manufacturing physical cameras"
        ],
        "answer": 3
    },
    {
        "section": "Applications of Computer Vision",
        "question": "Which of the following applications is commonly used in security systems and personal devices?",
        "options": [
            "Autonomous Vehicles",
            "Facial Recognition",
            "Medical Imaging",
            "Augmented Reality"
        ],
        "answer": 1
    },
    {
        "section": "Applications of Computer Vision",
        "question": "Which of the following applications uses real-time object detection and tracking?",
        "options": [
            "Medical Imaging",
            "Autonomous Vehicles",
            "Industrial Automation",
            "Facial Recognition"
        ],
        "answer": 1
    },
    {
        "section": "Applications of Computer Vision",
        "question": "Which of the following is an example of computer vision in healthcare?",
        "options": [
            "Detecting abnormalities in X-rays or MRIs",
            "Overlaying information on real-world objects",
            "Traffic sign recognition",
            "Face unlocking on smartphones"
        ],
        "answer": 0
    },
    {
        "section": "Image Processing vs Computer Vision",
        "question": "Image Processing mainly focuses on:",
        "options": [
            "High-level interpretation of images",
            "Improving image quality or preparing images for further analysis",
            "Understanding the semantic meaning of an image",
            "Decision-making based on analysis"
        ],
        "answer": 1
    },
    {
        "section": "Image Processing vs Computer Vision",
        "question": "Computer Vision mainly focuses on:",
        "options": [
            "Enhancing brightness and contrast of images",
            "Interpreting and understanding the content of images",
            "Creating new image filters",
            "Resizing and cropping images"
        ],
        "answer": 1
    },
    {
        "section": "Computer Vision Workflow",
        "question": "Which of the following represents the correct sequence of a computer vision workflow?",
        "options": [
            "Feature Extraction \u2192 Pre-processing \u2192 Image Acquisition \u2192 Interpretation \u2192 Decision Making",
            "Image Acquisition \u2192 Pre-processing \u2192 Feature Extraction \u2192 Interpretation \u2192 Decision Making",
            "Pre-processing \u2192 Decision Making \u2192 Image Acquisition \u2192 Feature Extraction \u2192 Interpretation",
            "Image Acquisition \u2192 Feature Extraction \u2192 Pre-processing \u2192 Decision Making \u2192 Interpretation"
        ],
        "answer": 1
    },
    {
        "section": "Computer Vision Workflow",
        "question": "Which stage of the workflow involves capturing images using cameras or loading them from storage?",
        "options": [
            "Feature Extraction",
            "Pre-processing",
            "Image Acquisition",
            "Decision Making"
        ],
        "answer": 2
    },
    {
        "section": "Computer Vision Workflow",
        "question": "Which step in the workflow focuses on resizing, normalization, and grayscale conversion?",
        "options": [
            "Image Acquisition",
            "Pre-processing",
            "Feature Extraction",
            "Interpretation"
        ],
        "answer": 1
    },
    {
        "section": "Computer Vision Workflow",
        "question": "Feature Extraction involves detecting:",
        "options": [
            "Edges, textures, and contours",
            "Camera resolution",
            "Noise in images",
            "File storage paths"
        ],
        "answer": 0
    },
    {
        "section": "Computer Vision Workflow",
        "question": "Decision Making in computer vision means:",
        "options": [
            "Taking an action based on analysis",
            "Enhancing contrast",
            "Capturing an image",
            "Improving resolution"
        ],
        "answer": 0
    },
    {
        "section": "Python Libraries",
        "question": "Which Python library is primarily used for computer vision tasks?",
        "options": [
            "TensorFlow",
            "OpenCV",
            "NumPy",
            "Matplotlib"
        ],
        "answer": 1
    },
    {
        "section": "Python Libraries",
        "question": "Which library is mainly used for numerical operations in image arrays?",
        "options": [
            "OpenCV",
            "Matplotlib",
            "NumPy",
            "scikit-image"
        ],
        "answer": 2
    },
    {
        "section": "Python Libraries",
        "question": "Which library is best for plotting and visualizing images?",
        "options": [
            "NumPy",
            "OpenCV",
            "Matplotlib",
            "scikit-learn"
        ],
        "answer": 2
    },
    {
        "section": "Python Libraries",
        "question": "Which library provides higher-level image processing functions?",
        "options": [
            "TensorFlow",
            "scikit-image",
            "PyTorch",
            "Keras"
        ],
        "answer": 1
    },
    {
        "section": "Python Libraries",
        "question": "Which library is widely used for deep learning in vision systems?",
        "options": [
            "OpenCV",
            "TensorFlow/Keras",
            "NumPy",
            "Matplotlib"
        ],
        "answer": 1
    },
    {
        "section": "Image Loading",
        "question": "Which OpenCV function is used to read an image file?",
        "options": [
            "cv2.read()",
            "cv2.imread()",
            "cv2.load()",
            "cv2.open()"
        ],
        "answer": 1
    },
    {
        "section": "Image Loading",
        "question": "By default, OpenCV loads images in which color format?",
        "options": [
            "RGB",
            "BGR",
            "HSV",
            "Gray"
        ],
        "answer": 1
    },
    {
        "section": "Image Conversion",
        "question": "Which function is used to convert images from BGR to RGB?",
        "options": [
            "cv2.convert()",
            "cv2.cvtColor()",
            "cv2.rgb()",
            "cv2.colorChange()"
        ],
        "answer": 1
    },

 {
    "section": "Computer Vision - Introduction",
    "question": "What is the primary goal of Computer Vision?",
    "options": [
      "To design better cameras and sensors",
      "To enable machines to interpret and understand visual information",
      "To create more realistic video games",
      "To replace human photographers"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Introduction",
    "question": "Computer Vision is a multidisciplinary field that combines computer science with which other fields?",
    "options": [
      "Biology and Chemistry",
      "Mathematics and Electrical Engineering",
      "Psychology and Sociology",
      "Literature and Art"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Introduction",
    "question": "In the analogy to human vision, what does the computer vision 'eye' do?",
    "options": [
      "Processes and interprets signals",
      "Captures image data (like a camera)",
      "Makes decisions based on analysis",
      "Stores memories of images"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Introduction",
    "question": "Which of the following is a key objective of computer vision?",
    "options": [
      "Increase internet bandwidth",
      "Recognize patterns in images",
      "Develop new programming languages",
      "Design user interfaces"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Introduction",
    "question": "What is an example of 'semantic understanding' in computer vision?",
    "options": [
      "Resizing an image",
      "Applying a filter to enhance colors",
      "Scene segmentation",
      "Counting the number of pixels"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Applications",
    "question": "Which application uses computer vision for real-time object detection and tracking?",
    "options": [
      "Word Processors",
      "Autonomous Vehicles",
      "Web Browsers",
      "Music Players"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Applications",
    "question": "Detecting abnormalities in X-rays or MRIs is an application of computer vision in which field?",
    "options": [
      "Industrial Automation",
      "Medical Imaging",
      "Augmented Reality",
      "Facial Recognition"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Applications",
    "question": "Which application involves overlaying digital information onto the physical world?",
    "options": [
      "Visual Inspection",
      "Augmented Reality",
      "Autonomous Navigation",
      "Facial Recognition"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Fundamentals",
    "question": "What is the main difference between Image Processing and Computer Vision?",
    "options": [
      "Image Processing is higher-level than Computer Vision",
      "Computer Vision interprets image content, while Image Processing improves quality",
      "They are exactly the same field",
      "Image Processing requires more computational power"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Workflow",
    "question": "What is the first step in the basic computer vision workflow?",
    "options": [
      "Pre-processing",
      "Feature Extraction",
      "Image Acquisition",
      "Decision Making"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Workflow",
    "question": "Which step involves improving image quality through resizing and color correction?",
    "options": [
      "Interpretation",
      "Pre-processing",
      "Image Acquisition",
      "Decision Making"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Workflow",
    "question": "Detecting edges, contours, or textures in an image is part of which workflow step?",
    "options": [
      "Image Acquisition",
      "Pre-processing",
      "Feature Extraction",
      "Decision Making"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Workflow",
    "question": "The final step of the computer vision workflow, where the system takes action, is called:",
    "options": [
      "Understanding",
      "Interpretation",
      "Decision Making",
      "Feature Extraction"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Tools",
    "question": "Which Python library is the primary open-source library for computer vision?",
    "options": [
      "NumPy",
      "Matplotlib",
      "OpenCV",
      "Pandas"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Tools",
    "question": "Which library is essential for numerical operations and manipulating image arrays in Python?",
    "options": [
      "OpenCV",
      "NumPy",
      "Matplotlib",
      "scikit-image"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Tools",
    "question": "Which library is commonly used for plotting and visualizing images and graphs in Python?",
    "options": [
      "OpenCV",
      "NumPy",
      "Matplotlib",
      "TensorFlow"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Tools",
    "question": "Which tool is used for deep learning-based vision systems?",
    "options": [
      "Matplotlib",
      "NumPy",
      "TensorFlow/Keras",
      "OpenCV"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Setup",
    "question": "What is the correct pip command to install OpenCV, NumPy, and Matplotlib?",
    "options": [
      "pip install computer-vision",
      "pip install opencv numpy matplotlib",
      "pip install cv2 plt np",
      "install opencv-python numpy matplotlib"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Code",
    "question": "Which OpenCV function is used to read an image from a file?",
    "options": [
      "cv2.load_image()",
      "cv2.imread()",
      "cv2.read()",
      "cv2.open()"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Code",
    "question": "By default, OpenCV loads images in which color format?",
    "options": [
      "RGB",
      "BGR",
      "Grayscale",
      "HSV"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Code",
    "question": "What is the purpose of the `cv2.cvtColor(image, cv2.COLOR_BGR2RGB)` function?",
    "options": [
      "To save the image to a file",
      "To convert the image from BGR to RGB color format for correct display",
      "To convert the image to grayscale",
      "To resize the image"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Code",
    "question": "Which Matplotlib function is used to display an image?",
    "options": [
      "plt.show()",
      "plt.display()",
      "plt.imshow()",
      "plt.plot()"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Code",
    "question": "What does `plt.axis('off')` do?",
    "options": [
      "Turns off the computer",
      "Hides the axis ticks and labels around the image",
      "Saves the image",
      "Increases the image contrast"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Code",
    "question": "What is the correct code to convert an image named `the_image` to grayscale?",
    "options": [
      "gray_image = cv2.cvtColor(the_image, cv2.COLOR_RGB2GRAY)",
      "gray_image = cv2.cvtColor(the_image, cv2.COLOR_BGR2GRAY)",
      "gray_image = cv2.grayscale(the_image)",
      "gray_image = the_image.to_gray()"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Code",
    "question": "When displaying a grayscale image with Matplotlib, what parameter must be set in `plt.imshow()`?",
    "options": [
      "title='Grayscale Image'",
      "axis='off'",
      "cmap='gray'",
      "format='png'"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Data",
    "question": "What does `image.shape` return for a color image?",
    "options": [
      "(width, height)",
      "(height, width, channels)",
      "(channels, height, width)",
      "(height, width)"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Data",
    "question": "What does `image.shape` return for a grayscale image?",
    "options": [
      "(width, height)",
      "(height, width, channels)",
      "(channels, height, width)",
      "(height, width)"
    ],
    "answer": 3
  },
  {
    "section": "Computer Vision - Concepts",
    "question": "What is the main benefit of converting an image to grayscale?",
    "options": [
      "It makes the image file size larger",
      "It simplifies image data by removing color information, which is useful for tasks like edge detection",
      "It always improves the image resolution",
      "It adds more colors to the image"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Applications",
    "question": "Visual inspection on an assembly line is an example of computer vision in:",
    "options": [
      "Medical Imaging",
      "Industrial Automation",
      "Augmented Reality",
      "Autonomous Vehicles"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Applications",
    "question": "Unlocking a smartphone using a face scan is an application of:",
    "options": [
      "Medical Imaging",
      "Facial Recognition",
      "Augmented Reality",
      "Industrial Automation"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Workflow",
    "question": "The step 'Classification, detection, or segmentation' falls under which part of the workflow?",
    "options": [
      "Image Acquisition",
      "Pre-processing",
      "Feature Extraction",
      "Understanding / Interpretation"
    ],
    "answer": 3
  },
  {
    "section": "Computer Vision - Tools",
    "question": "Which library is described as offering 'extensive functions for image and video analysis, camera calibration, object tracking'?",
    "options": [
      "NumPy",
      "Matplotlib",
      "OpenCV",
      "scikit-image"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Code",
    "question": "What is the purpose of the `plt.show()` function?",
    "options": [
      "To load an image from disk",
      "To convert an image to grayscale",
      "To render and display the image window",
      "To install the matplotlib library"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Fundamentals",
    "question": "The ultimate goal of a computer vision system is to:",
    "options": [
      "Capture the highest resolution image possible",
      "Make decisions based on visual analysis",
      "Store millions of images efficiently",
      "Display images on a screen"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Setup",
    "question": "What is the name of the Python package for OpenCV that is installed via pip?",
    "options": [
      "cv2",
      "opencv",
      "opencv-python",
      "python-opencv"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Code",
    "question": "In the code `print(\"Original Image Shape:\", image1.shape)`, what will be printed for a 640x480 color image?",
    "options": [
      "(640, 480)",
      "(480, 640, 3)",
      "(3, 480, 640)",
      "(480, 640)"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Code",
    "question": "In the code `print(\"Grayscale Image Shape:\", gray_image.shape)`, what will be printed for a 640x480 image?",
    "options": [
      "(640, 480)",
      "(480, 640, 1)",
      "(480, 640)",
      "(1, 480, 640)"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Practical",
    "question": "What is the final step in the suggested practical exercise?",
    "options": [
      "Load an image file",
      "Convert it to grayscale",
      "Display both images",
      "Save the grayscale image"
    ],
    "answer": 3
  },
  {
    "section": "Computer Vision - Concepts",
    "question": "What does the 'vision' in 'Computer Vision' refer to?",
    "options": [
      "The ability to display graphics on a monitor",
      "The ability to interpret and understand visual information from the world",
      "The technology behind virtual reality headsets",
      "The resolution of a camera sensor"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - History",
    "question": "The field of Computer Vision aims to replicate the capabilities of:",
    "options": [
      "A printer",
      "Human vision",
      "A digital calculator",
      "A radio"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Workflow",
    "question": "Which step would involve normalizing pixel values?",
    "options": [
      "Image Acquisition",
      "Pre-processing",
      "Feature Extraction",
      "Decision Making"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Tools",
    "question": "Which library is described as 'higher-level image processing'?",
    "options": [
      "OpenCV",
      "NumPy",
      "Matplotlib",
      "scikit-image"
    ],
    "answer": 3
  },
  {
    "section": "Computer Vision - Code",
    "question": "What is the correct function to save an image named `gray_image` to a file called 'output.jpg'?",
    "options": [
      "cv2.save_image(gray_image, 'output.jpg')",
      "cv2.write(gray_image, 'output.jpg')",
      "cv2.imsave('output.jpg', gray_image)",
      "cv2.imwrite('output.jpg', gray_image)"
    ],
    "answer": 3
  },
  {
    "section": "Computer Vision - Applications",
    "question": "Which of these is NOT a typical application of computer vision mentioned in the slides?",
    "options": [
      "Facial Recognition",
      "Autonomous Vehicles",
      "Medical Imaging",
      "Text Editing"
    ],
    "answer": 3
  },
  {
    "section": "Computer Vision - Fundamentals",
    "question": "What is the input to a computer vision system?",
    "options": [
      "Text commands",
      "Audio signals",
      "Digital images or videos",
      "Electrical pulses"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Fundamentals",
    "question": "What is the output of a computer vision system?",
    "options": [
      "A rendered 3D model",
      "A new image file",
      "Meaningful insights or decisions based on visual data",
      "A printed photograph"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Introduction",
    "question": "Why is computer vision considered a challenging field?",
    "options": [
      "Because computers are not powerful enough",
      "Because it is easy for humans but difficult to formalize for machines",
      "Because there are no good libraries available",
      "Because images are always in black and white"
    ],
    "answer": 1
  },




  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "A digital image is fundamentally represented as a discrete grid of:",
    "options": ["Vectors", "Pixels", "Matrices", "Functions"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "In mathematical terms, a grayscale image can be defined as a 2D function f(x, y) where the output value typically ranges from:",
    "options": ["0 to 1", "0 to 255", "0 to 100", "-128 to 127"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "What does the resolution of a digital image refer to?",
    "options": ["The number of colors it can represent", "The physical size of the image when printed", "The number of pixels along its width and height", "The amount of compression applied"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "An image with a resolution of 1920x1080 has how many total pixels?",
    "options": ["1,920,000", "2,073,600", "108,000", "3,840"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "The proportion of an image's width to its height is known as its:",
    "options": ["Resolution", "Pixel Density", "Aspect Ratio", "Scale"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "Which color model is described as 'additive' and creates colors by combining Red, Green, and Blue light?",
    "options": ["HSV", "CMYK", "Grayscale", "RGB"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "In the RGB color model, each color channel's intensity is typically represented by a value between:",
    "options": ["0 and 1", "0 and 100", "0 and 255", "-128 and 127"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "Which of the following is the standard formula for converting an RGB image to grayscale using the luminosity method?",
    "options": ["Gray = (R + G + B) / 3", "Gray = 0.333*R + 0.333*G + 0.333*B", "Gray = 0.299*R + 0.587*G + 0.114*B", "Gray = max(R, G, B)"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "The HSV color model separates color information into three components. What does 'H' stand for?",
    "options": ["Height", "Hue", "Highlights", "Harmony"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "In the HSV model, which component represents the purity or vividness of the color?",
    "options": ["Hue", "Saturation", "Value", "Variance"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "Which color space is specifically designed to be based on human perception of color?",
    "options": ["RGB", "HSV", "LAB", "YCrCb"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "The YCrCb color space is primarily used in:",
    "options": ["Printing", "Video Compression", "Medical Imaging", "Astrophotography"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "Which color model uses Cyan, Magenta, Yellow, and Key (Black) and is common in printing?",
    "options": ["RGB", "HSV", "CMYK", "LAB"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "How many channels does a standard RGB color image have?",
    "options": ["1", "2", "3", "4"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "A grayscale image consists of:",
    "options": ["3 channels", "2 channels", "1 channel", "No channels"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "The numerical value representing the brightness or color of a pixel is called its:",
    "options": ["Resolution", "Bit Depth", "Pixel Intensity", "Aspect Value"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "An 8-bit grayscale image can have how many possible intensity values?",
    "options": ["2", "8", "256", "16.7 million"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "A 24-bit color image uses how many bits per RGB channel?",
    "options": ["1 bit", "8 bits", "24 bits", "32 bits"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "In Python with OpenCV, a color image is typically stored as a:",
    "options": ["List", "Dictionary", "NumPy array", "String"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "What is the shape of the NumPy array for a 512x512 RGB image?",
    "options": ["(512, 512)", "(512, 512, 1)", "(512, 512, 3)", "(3, 512, 512)"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "Data such as resolution, color model, and camera settings stored within an image file is called:",
    "options": ["Megadata", "Infodata", "Metadata", "Paradata"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "For which computer vision task is the HSV color space often preferred over RGB due to its illumination invariance?",
    "options": ["Edge Detection", "Image Compression", "Color Filtering/Detection", "Image Sharpening"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "Which color space is commonly used for skin detection?",
    "options": ["RGB and Grayscale", "HSV and YCrCb", "CMYK and LAB", "RGB only"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "Converting an image to grayscale is often a preprocessing step for what task to simplify computation?",
    "options": ["Color Correction", "Edge Detection", "White Balancing", "Format Conversion"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "What is the correct command to install the OpenCV library for Python using pip?",
    "options": ["pip install opencv", "pip install cv2", "pip install opencv-python", "pip install opencv-library"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "In OpenCV, which function is used to read an image from a file?",
    "options": ["cv2.read()", "cv2.load()", "cv2.imload()", "cv2.imread()"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "What does the following OpenCV code snippet do? 'cv2.waitKey(0)'",
    "options": ["Saves the image", "Displays the image for 0 milliseconds", "Waits indefinitely for a key press", "Closes all windows immediately"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "Which OpenCV function is used to convert a BGR image to grayscale?",
    "options": ["cv2.toGrayscale()", "cv2.grayscale()", "cv2.cvtColor() with COLOR_BGR2GRAY", "cv2.convert(GRAY)"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "In OpenCV, the 'cv2.split(img)' function on a BGR image returns:",
    "options": ["The image dimensions", "Three separate channels: Blue, Green, Red", "The image histogram", "A grayscale version"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "What is the correct function to save an image to a file in OpenCV?",
    "options": ["cv2.save()", "cv2.write()", "cv2.imsave()", "cv2.imwrite()"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "What does 'img.shape' return for a color image in OpenCV?",
    "options": ["File size in bytes", "(Width, Height)", "(Height, Width, Channels)", "(Channels, Height, Width)"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "In OpenCV, color images are loaded by default in which color model?",
    "options": ["RGB", "BGR", "HSV", "Grayscale"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "To convert a BGR image to HSV in OpenCV, you would use:",
    "options": ["cv2.COLOR_BGR2HSV", "cv2.COLOR_HSV2BGR", "cv2.COLOR_RGB2HSV", "cv2.COLOR_BGR2GRAY"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "A low-resolution image is typically characterized by:",
    "options": ["Larger file size and more detail", "Smaller file size and less detail", "Higher bit depth", "More color channels"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "The 'Value' component in the HSV model is most closely related to:",
    "options": ["Color type", "Color purity", "Brightness", "Contrast"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "The LAB color space consists of which components?",
    "options": ["Luma, Alpha, Beta", "Lightness, A, B", "Luminance, Angle, Brightness", "Length, Aspect, Breadth"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "Which of these is NOT a typical step in basic image processing with OpenCV?",
    "options": ["cv2.imread()", "cv2.imshow()", "cv2.compile()", "cv2.waitKey()"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "The total number of unique colors a 24-bit RGB image can represent is approximately:",
    "options": ["256 thousand", "16.7 million", "65 thousand", "4.2 billion"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "Which OpenCV function is used to destroy all open image windows?",
    "options": ["cv2.closeAll()", "cv2.destroyAllWindows()", "cv2.quit()", "cv2.windowClose()"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "The primary reason for using the YCrCb color space in video compression is that:",
    "options": ["It has more colors than RGB", "Human vision is more sensitive to luma (Y) than chroma (Cr/Cb)", "It is easier to process", "It is the native format of all cameras"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "If you access a pixel in a BGR image at position (y, x) using `img[y, x]` in OpenCV, what will it return?",
    "options": ["A single integer", "A list of [B, G, R] values", "A list of [R, G, B] values", "The pixel's HSV values"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "Compared to its RGB version, a grayscale version of the same image will have a:",
    "options": ["Larger file size", "Smaller file size", "Identical file size", "More colorful appearance"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "The process of analyzing the distribution of pixel intensities in an image is done using a:",
    "options": ["Pie Chart", "Scatter Plot", "Histogram", "Line Graph"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "Which of these is a key advantage of the HSV color model?",
    "options": ["It is the native format for displays", "It separates color information from intensity", "It uses less memory than RGB", "It is required for printing"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "In a digital image, the spatial coordinates (x, y) refer to the:",
    "options": ["Color values of a pixel", "Location of a pixel in the grid", "Bit depth of the image", "File format metadata"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "The field of computer vision aims to:",
    "options": ["Build faster computer processors", "Enable computers to derive information from visual data", "Design more ergonomic computer mice", "Create larger computer monitors"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "Which OpenCV function would you use to display an image in a window?",
    "options": ["cv2.show()", "cv2.display()", "cv2.imshow()", "cv2.preview()"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "A binary image (black and white only) has a bit depth of:",
    "options": ["1-bit", "8-bit", "16-bit", "24-bit"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Digital Images & Color Models",
    "question": "What is a common first step in most computer vision pipelines?",
    "options": ["Model Training", "Data Augmentation", "Image Acquisition", "Hyperparameter Tuning"],
    "answer": 2
  },
   {
        "section": "Template Matching",
        "question": "Template matching is mainly used for:",
        "options": [
            "Finding parts of an image that match a given template",
            "Converting images to grayscale",
            "Segmenting objects based on edges",
            "Enhancing image contrast"
        ],
        "answer": 0
    },
    {
        "section": "Template Matching",
        "question": "Which method in OpenCV performs template matching?",
        "options": [
            "cv2.findContours()",
            "cv2.matchTemplate()",
            "cv2.detectFeatures()",
            "cv2.threshold()"
        ],
        "answer": 1
    },
    {
        "section": "Template Matching",
        "question": "The output of cv2.matchTemplate() is:",
        "options": [
            "A grayscale image",
            "A heatmap of match scores",
            "A binary thresholded image",
            "A list of contour points"
        ],
        "answer": 1
    },
    {
        "section": "Template Matching",
        "question": "In OpenCV template matching, for TM_CCOEFF and TM_CCORR methods the best match is found using:",
        "options": [
            "minLoc",
            "maxLoc",
            "center point",
            "random pixel"
        ],
        "answer": 1
    },
    {
        "section": "Template Matching",
        "question": "Which of the following is a limitation of template matching?",
        "options": [
            "It is robust to scale and rotation",
            "It is sensitive to changes in scale, rotation, and lighting",
            "It always detects multiple objects",
            "It cannot use correlation-based similarity"
        ],
        "answer": 1
    },
    {
        "section": "Template Matching",
        "question": "Template matching can be used in applications such as:",
        "options": [
            "Logo detection",
            "Facial part localization",
            "Object tracking",
            "All of the above"
        ],
        "answer": 3
    },
    {
        "section": "Template Matching",
        "question": "Which OpenCV function is used to find the minimum and maximum values in the result matrix of template matching?",
        "options": [
            "cv2.locateMax()",
            "cv2.findContours()",
            "cv2.minMaxLoc()",
            "cv2.threshold()"
        ],
        "answer": 2
    },
    {
        "section": "Template Matching",
        "question": "Template matching is most suitable for detecting:",
        "options": [
            "Objects with variable lighting",
            "Objects with fixed patterns",
            "Objects with random noise",
            "Dynamic motion blur"
        ],
        "answer": 1
    },
    {
        "section": "Template Matching",
        "question": "Which visualization technique can be used to analyze the result of template matching?",
        "options": [
            "cv2.cvtColor()",
            "matplotlib.pyplot.imshow()",
            "cv2.threshold()",
            "cv2.drawContours()"
        ],
        "answer": 1
    },
    {
        "section": "Template Matching",
        "question": "Template matching is a __________ method.",
        "options": [
            "Histogram-based",
            "Sliding window",
            "Fourier transform",
            "Machine learning"
        ],
        "answer": 1
    },
    {
        "section": "Contour Detection",
        "question": "A contour in image processing is best described as:",
        "options": [
            "A filled region of color",
            "A curve joining continuous points along the boundary of an object",
            "A histogram of pixel intensities",
            "A collection of disconnected points in an image"
        ],
        "answer": 1
    },
    {
        "section": "Contour Detection",
        "question": "Contours are typically extracted from:",
        "options": [
            "RGB images",
            "HSV images",
            "Binary or edge-detected images",
            "3D point clouds"
        ],
        "answer": 2
    },
    {
        "section": "Contour Detection",
        "question": "Before detecting contours, an image is usually:",
        "options": [
            "Converted to grayscale, smoothed, and thresholded or edge-detected",
            "Converted to HSV and sharpened",
            "Converted to RGB and enhanced",
            "Segmented using clustering"
        ],
        "answer": 0
    },
    {
        "section": "Contour Detection",
        "question": "Which OpenCV function is used to detect contours?",
        "options": [
            "cv2.threshold()",
            "cv2.findContours()",
            "cv2.drawContours()",
            "cv2.matchTemplate()"
        ],
        "answer": 1
    },
    {
        "section": "Contour Detection",
        "question": "In cv2.findContours(), cv2.RETR_EXTERNAL is used to:",
        "options": [
            "Retrieve all nested contours",
            "Retrieve only the outermost contours",
            "Retrieve contours by color",
            "Retrieve contour hierarchy fully"
        ],
        "answer": 1
    },
    {
        "section": "Contour Detection",
        "question": "Which approximation method compresses contour points to save memory?",
        "options": [
            "CHAIN_APPROX_NONE",
            "CHAIN_APPROX_SIMPLE",
            "CHAIN_APPROX_COMPLEX",
            "CHAIN_MEMORY_SAVE"
        ],
        "answer": 1
    },
    {
        "section": "Contour Detection",
        "question": "Which OpenCV function is used to draw contours on an image?",
        "options": [
            "cv2.drawContours()",
            "cv2.showContours()",
            "cv2.contourPlot()",
            "cv2.line()"
        ],
        "answer": 0
    },
    {
        "section": "Contour Detection",
        "question": "Which of the following properties can be calculated from contours?",
        "options": [
            "Area",
            "Perimeter",
            "Bounding box",
            "All of the above"
        ],
        "answer": 3
    },
    {
        "section": "Contour Detection",
        "question": "The function cv2.contourArea() is used to calculate:",
        "options": [
            "Area of a contour",
            "Length of a contour",
            "Centroid of a contour",
            "Polygon approximation"
        ],
        "answer": 0
    },
    {
        "section": "Contour Detection",
        "question": "The function cv2.arcLength() is used to calculate:",
        "options": [
            "Area of a contour",
            "Bounding rectangle",
            "Perimeter (arc length) of a contour",
            "Circle enclosing a contour"
        ],
        "answer": 2
    },
 



    {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What is the primary purpose of template matching?",
    "options": [
      "To change the color space of an image",
      "To find parts of an image that match a given template image",
      "To resize an image to a smaller resolution",
      "To apply artistic filters to an image"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "How is template matching best described?",
    "options": [
      "A deep learning method",
      "A sliding window method that uses similarity measures",
      "A contour detection algorithm",
      "A color correction technique"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "Which of the following is a common application of template matching?",
    "options": [
      "Image resizing",
      "Logo detection",
      "Color enhancement",
      "Video compression"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "Which OpenCV function is used to perform template matching?",
    "options": [
      "cv2.matchTemplate()",
      "cv2.findContours()",
      "cv2.templateFind()",
      "cv2.correlate()"
    ],
    "answer": 0
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "The result of cv2.matchTemplate() is a:",
    "options": [
      "Binary image",
      "Grayscale image",
      "Heatmap (response map) of match scores",
      "List of contours"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "For the TM_SQDIFF method, the best match is found using:",
    "options": [
      "maxLoc",
      "minLoc",
      "meanLoc",
      "medianLoc"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "A major limitation of template matching is its lack of robustness to:",
    "options": [
      "Color changes",
      "Scale and rotation",
      "Noise in the template",
      "All of the above"
    ],
    "answer": 3
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What is a contour in image processing?",
    "options": [
      "The color palette of an image",
      "A curve that joins all continuous points along a boundary with the same color or intensity",
      "The metadata of an image file",
      "A filter applied to blur an image"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "Contours are essential for all of the following EXCEPT:",
    "options": [
      "Shape analysis",
      "Object detection and recognition",
      "Changing the image file format",
      "Measuring geometrical properties"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "Before extracting contours, an image must typically be:",
    "options": [
      "Converted to grayscale and thresholded or edge-detected",
      "Converted to HSV color space",
      "Compressed to a JPEG format",
      "Displayed on a screen"
    ],
    "answer": 0
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What is the standard image processing pipeline for contour detection?",
    "options": [
      "Original → Blur → Grayscale → Threshold → Contour",
      "Original → Grayscale → Blur → Threshold → Contour",
      "Threshold → Original → Grayscale → Blur → Contour",
      "Grayscale → Original → Threshold → Blur → Contour"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "Which OpenCV function is used to detect contours in a binary image?",
    "options": [
      "cv2.drawContours()",
      "cv2.findContours()",
      "cv2.contourArea()",
      "cv2.detectEdges()"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What does the `cv2.RETR_EXTERNAL` retrieval mode do?",
    "options": [
      "Retrieves all contours and establishes a full hierarchy",
      "Retrieves only the outermost contours, ignoring nested ones",
      "Retrieves only the innermost contours",
      "Retrieves contours without any hierarchy"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What is the purpose of the `cv2.CHAIN_APPROX_SIMPLE` approximation method?",
    "options": [
      "It keeps all points on the contour, using more memory",
      "It compresses contour points to save memory (e.g., only endpoints of straight lines)",
      "It draws the contours in a different color",
      "It smoothens the contour by applying a blur"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "Which function is used to draw contours on an image?",
    "options": [
      "cv2.findContours()",
      "cv2.showContours()",
      "cv2.drawContours()",
      "cv2.plotContours()"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "In `cv2.drawContours(img, contours, -1, (0, 255, 0), 2)`, what does the '-1' parameter specify?",
    "options": [
      "Draw the first contour only",
      "Draw no contours",
      "Draw all contours",
      "The line thickness"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What does the `cv2.contourArea()` function compute?",
    "options": [
      "The perimeter of the contour",
      "The color intensity within the contour",
      "The area enclosed by the contour",
      "The center point of the contour"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What does the `cv2.arcLength()` function compute?",
    "options": [
      "The area of the contour",
      "The perimeter (arc length) of the contour",
      "The bounding box of the contour",
      "The circularity of the contour"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "Which function is used to get a bounding rectangle around a contour?",
    "options": [
      "cv2.contourArea()",
      "cv2.boundingRect()",
      "cv2.arcLength()",
      "cv2.approxPolyDP()"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What is the purpose of `cv2.approxPolyDP()`?",
    "options": [
      "To calculate the area of a contour",
      "To simplify a contour by reducing the number of points",
      "To convert a contour to a binary image",
      "To find the center of mass of a contour"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "The `epsilon` parameter in `cv2.approxPolyDP` controls:",
    "options": [
      "The color of the approximated polygon",
      "The accuracy of the approximation (higher epsilon = greater simplification)",
      "The line thickness of the drawn polygon",
      "The retrieval mode for the contour"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "Polygon approximation with `cv2.approxPolyDP` is commonly used for:",
    "options": [
      "Blurring an image",
      "Shape detection (e.g., triangle, rectangle)",
      "Changing image resolution",
      "Template matching"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "Why is preprocessing (blur, threshold) crucial before contour detection?",
    "options": [
      "To make the image file size smaller",
      "To reduce noise and create clear object boundaries in a binary image",
      "To convert the image to a different color space",
      "To draw the contours faster"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What does the hierarchy output from `cv2.findContours()` describe?",
    "options": [
      "The color values of the contours",
      "The parent-child relationships between contours (e.g., one contour inside another)",
      "The area and perimeter of each contour",
      "The computational time taken to find the contours"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "Which retrieval mode would you use to get ALL contours and their hierarchical relationships?",
    "options": [
      "cv2.RETR_EXTERNAL",
      "cv2.RETR_LIST",
      "cv2.RETR_TREE",
      "cv2.RETR_SIMPLE"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "In the code `_, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)`, what does the value 127 represent?",
    "options": [
      "The maximum value to assign",
      "The threshold value; pixels >127 become 255",
      "The line thickness for drawing",
      "The number of contours to find"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What is the output of the thresholding function?",
    "options": [
      "A grayscale image",
      "A color image",
      "A binary image (black and white)",
      "A list of points"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "To filter out small, noisy contours, you would use:",
    "options": [
      "cv2.approxPolyDP()",
      "cv2.contourArea() with an if-statement",
      "cv2.arcLength()",
      "A different retrieval mode"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "Which of these is a real-world application of contour detection?",
    "options": [
      "Object tracking in video",
      "Logo detection in images",
      "Medical image segmentation",
      "All of the above"
    ],
    "answer": 3
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What is the correct order of parameters for `cv2.rectangle` to draw a box around a match?",
    "options": [
      "(image, bottom_right, top_left, color, thickness)",
      "(image, top_left, bottom_right, color, thickness)",
      "(top_left, bottom_right, image, color, thickness)",
      "(color, top_left, bottom_right, image, thickness)"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "After finding the best match location with template matching, how do you calculate the bottom_right coordinate?",
    "options": [
      "bottom_right = (top_left[0] - w, top_left[1] - h)",
      "bottom_right = (top_left[0], top_left[1])",
      "bottom_right = (top_left[0] + w, top_left[1] + h)",
      "bottom_right = (max_loc[0], max_loc[1])"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What does `cv2.minMaxLoc(result)` return?",
    "options": [
      "The minimum and maximum values in the result array, and their locations",
      "The mean and median of the result array",
      "The dimensions of the template",
      "The contours found in the image"
    ],
    "answer": 0
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "For which method would you use the `max_loc` from `minMaxLoc` to find the best match?",
    "options": [
      "TM_SQDIFF",
      "TM_SQDIFF_NORMED",
      "TM_CCOEFF_NORMED",
      "None of the above"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What is the primary input to `cv2.findContours`?",
    "options": [
      "A color image",
      "A grayscale image",
      "A binary image",
      "A template image"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "The second argument to `cv2.findContours` specifies the:",
    "options": [
      "Contour approximation method",
      "Contour retrieval mode",
      "Output image",
      "Line thickness"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "The third argument to `cv2.findContours` specifies the:",
    "options": [
      "Contour retrieval mode",
      "Contour approximation method",
      "Hierarchy output",
      "Input image"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What is the data type of the `contours` variable returned by `cv2.findContours`?",
    "options": [
      "A single NumPy array",
      "A list of NumPy arrays",
      "A dictionary of points",
      "An integer value"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "How can you visualize the result matrix from template matching for debugging?",
    "options": [
      "With cv2.imshow('Result', result)",
      "With matplotlib.pyplot.imshow(result)",
      "With cv2.findContours(result)",
      "It cannot be visualized"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What is a common technique to find multiple matches using template matching?",
    "options": [
      "Using a larger template",
      "Using thresholding on the result heatmap",
      "Using contour detection on the template",
      "Converting the image to grayscale"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "Which step is necessary to keep an OpenCV window open to view the result?",
    "options": [
      "cv2.destroyAllWindows()",
      "cv2.waitKey(0)",
      "cv2.imwrite()",
      "cv2.drawContours()"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What does `cv2.boundingRect(cnt)` return?",
    "options": [
      "The area and perimeter of the contour",
      "The (x, y) coordinates of the centroid",
      "The (x, y, width, height) of the bounding rectangle",
      "A simplified polygon of the contour"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "The formula `epsilon = 0.02 * cv2.arcLength(cnt, True)` is used for:",
    "options": [
      "Calculating contour area",
      "Setting the accuracy parameter for polygon approximation",
      "Setting the threshold value for binarization",
      "Calculating the aspect ratio of the bounding box"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "If `cv2.approxPolyDP` returns a contour with 3 vertices, the shape is likely a:",
    "options": [
      "Circle",
      "Square",
      "Triangle",
      "Line"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "If `cv2.approxPolyDP` returns a contour with 4 vertices, the shape is likely a:",
    "options": [
      "Circle",
      "Square or Rectangle",
      "Pentagon",
      "Triangle"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What is the key conceptual difference between template matching and contour detection?",
    "options": [
      "Template matching finds a specific pattern, contour detection finds general boundaries",
      "Contour detection is faster than template matching",
      "Template matching requires a binary image",
      "Contour detection uses a sliding window"
    ],
    "answer": 0
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "Which of these is a typical use case for template matching over contour analysis?",
    "options": [
      "Finding the outline of any object",
      "Measuring the area of a random blob",
      "Finding a specific logo with a known appearance",
      "Detecting all edges in an image"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "Which of these is a typical use case for contour analysis over template matching?",
    "options": [
      "Finding a specific facial feature in an image",
      "Detecting and measuring unknown objects based on their shape",
      "Matching a printed character",
      "Tracking a specific object in a video"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision - Template Matching & Contours",
    "question": "What is the final step in any OpenCV script that displays images?",
    "options": [
      "cv2.imshow()",
      "cv2.waitKey(0)",
      "cv2.destroyAllWindows()",
      "All of the above are necessary"
    ],
    "answer": 3
  },
      {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What do geometric transformations modify in an image?",
    "options": ["The color values of pixels", "The spatial relationship of pixels", "The image's file format", "The image's bit depth"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "Which of the following is NOT a type of geometric transformation mentioned?",
    "options": ["Translation", "Scaling", "Rotation", "Convolution"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What is the primary purpose of an image histogram?",
    "options": ["To change the color space of an image", "To show the distribution of pixel intensity values", "To apply a filter to an image", "To save the image to a file"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "In a grayscale image histogram, what does the x-axis represent?",
    "options": ["Number of pixels", "Spatial coordinates (x, y)", "Pixel Intensity values (0-255)", "Color channels"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "In a grayscale image histogram, what does the y-axis represent?",
    "options": ["Number of pixels for each intensity", "Intensity values", "Saturation levels", "Hue values"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "A narrow, concentrated histogram typically indicates an image with:",
    "options": ["High contrast", "Low contrast", "Many colors", "A high resolution"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "For an 8-bit grayscale image, how many bins does its histogram typically have?",
    "options": ["128", "255", "256", "512"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "How is a color histogram different from a grayscale histogram?",
    "options": ["It has fewer bins", "It plots separate histograms for each color channel", "It uses a logarithmic scale", "It only shows brightness, not color"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "Which OpenCV function is used to calculate a histogram?",
    "options": ["cv2.hist()", "cv2.calcHist()", "cv2.computeHistogram()", "cv2.plotHist()"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "In the `cv2.calcHist([img], [channel], None, [256], [0, 256])` function call, what does the `[channel]` parameter specify?",
    "options": ["The mask to apply", "The color channel index to compute the histogram for", "The number of bins", "The range of values"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What is the purpose of the `.ravel()` function when plotting a histogram with `plt.hist()`?",
    "options": ["To convert the image to a different color space", "To flatten the 2D image array into a 1D array", "To increase the image contrast", "To save the image"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "Why is it important to convert a BGR image to RGB when plotting color histograms with Matplotlib?",
    "options": ["To reduce file size", "To calculate the histogram faster", "Because Matplotlib expects images in RGB order", "To apply histogram equalization"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What is the main goal of histogram equalization?",
    "options": ["To reduce image noise", "To decrease the image file size", "To enhance image contrast by spreading out intensity values", "To convert a color image to grayscale"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "Which OpenCV function is used for global histogram equalization on a grayscale image?",
    "options": ["cv2.filter2D()", "cv2.equalizeHist()", "cv2.normalize()", "cv2.threshold()"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "A key problem with global histogram equalization is that it can:",
    "options": ["Change the image dimensions", "Over-amplify noise in homogeneous regions", "Be too slow to compute", "Only work on color images"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What does CLAHE stand for?",
    "options": ["Constant Linear Adaptive Histogram Enhancement", "Contrast Limited Adaptive Histogram Equalization", "Color Level Adjustment for Histogram Equalization", "Cumulative Linear Adaptive Histogram Extension"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "How does CLAHE differ from standard histogram equalization?",
    "options": ["It works on the whole image at once", "It divides the image into tiles and processes each one separately", "It only works on color images", "It is a type of geometric transformation"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "Which of the following is a parameter for creating a CLAHE object in OpenCV?",
    "options": ["clipLimit", "binSize", "equalizeFactor", "contrastRatio"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "CLAHE is particularly useful for enhancing which type of images?",
    "options": ["Cartoon animations", "Medical images and fingerprints", "Landscape photographs", "Abstract art"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "The process of converting a grayscale image to a binary image (black and white) is known as:",
    "options": ["Histogram Equalization", "Thresholding", "Filtering", "Transformation"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "Which thresholding method applies varying thresholds to different regions of the same image?",
    "options": ["Global Thresholding", "Otsu's Thresholding", "Adaptive Thresholding", "Binary Thresholding"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "Otsu's Binarization is an automatic thresholding technique that finds the optimal threshold by:",
    "options": ["Asking the user for input", "Minimizing the intra-class variance", "Maximizing the overall image brightness", "Using a fixed value of 127"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What is a common application of thresholding in computer vision?",
    "options": ["Color correction", "Image segmentation", "Video playback", "3D modeling"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "In OpenCV, which function is used for simple thresholding?",
    "options": ["cv2.threshold()", "cv2.adaptiveThreshold()", "cv2.binarize()", "cv2.filter()"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "Geometric transformations are fundamental for:",
    "options": ["Changing the color model", "Image registration and stitching", "Calculating histograms", "Reducing image noise"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What does the `cv2.IMREAD_GRAYSCALE` flag do?",
    "options": ["Saves an image as grayscale", "Loads an image directly as a 1-channel grayscale image", "Converts a color image to HSV", "Applies a Gaussian blur"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "When using `cv2.calcHist`, what does the `histSize` parameter define?",
    "options": ["The physical size of the output graph", "The number of bins in the histogram", "The mask to use", "The color channel to use"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "After performing histogram equalization, the resulting histogram is typically:",
    "options": ["Narrower and taller", "Wider and more spread out", "Unchanged", "Split into three parts"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "Which library is commonly used alongside OpenCV for plotting histograms and images?",
    "options": ["TensorFlow", "PyTorch", "Matplotlib", "NumPy"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What is the main advantage of adaptive thresholding over global thresholding?",
    "options": ["It is faster to compute", "It can handle different lighting conditions in different parts of an image", "It produces a color output", "It is easier to implement"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "The 'L' in CLAHE stands for:",
    "options": ["Linear", "Limited", "Local", "Luminous"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What does the 'clipLimit' parameter control in CLAHE?",
    "options": ["The size of the image tiles", "The contrast limit for histogram clipping", "The number of output colors", "The speed of the algorithm"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "For a channel in a color image, if its histogram is skewed heavily to the left (toward 0), what does that indicate?",
    "options": ["That channel is very bright in the image", "That channel has very low intensity in the image", "The image has high contrast", "The image is in grayscale"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "Which application is NOT typically associated with using histograms?",
    "options": ["Contrast enhancement", "Thresholding", "Image segmentation", "Geometric translation"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "The process of 'backprojection' uses histograms for:",
    "options": ["Locating a known object in a new image", "Rotating an image", "Saving an image in a compressed format", "Converting an image to a different color space"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What is the final step typically required to keep an image window open when using `cv2.imshow()`?",
    "options": ["cv2.destroyAllWindows()", "cv2.waitKey(0)", "cv2.keepOpen()", "plt.show()"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "If an image has a high number of pixels at intensity 0, its histogram will have a:",
    "options": ["High peak at the right end", "High peak at the left end", "Even distribution across all intensities", "Gap in the middle"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What does a bimodal histogram suggest?",
    "options": ["The image is mostly a single color", "The image has two dominant groups of intensities (e.g., a dark foreground on a bright background)", "The image is corrupted", "The image has been equalized"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "Otsu's method is particularly effective for images with:",
    "options": ["A unimodal histogram", "A bimodal histogram", "Color gradients", "No texture"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "Which thresholding method would you choose for an image with uneven lighting?",
    "options": ["Global thresholding with a value of 127", "Otsu's method", "Adaptive thresholding", "No thresholding is possible"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What is the primary use of geometric transformations in the context of machine learning?",
    "options": ["To reduce model size", "For data augmentation", "To label training data", "To deploy models faster"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What is the correct order of parameters for the `cv2.threshold()` function?",
    "options": ["(src, thresh, maxval, type)", "(src, type, thresh, maxval)", "(thresh, src, maxval, type)", "(maxval, thresh, src, type)"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What does the `cv2.THRESH_BINARY` flag do in the `cv2.threshold()` function?",
    "options": ["Sets pixels above the threshold to 0", "Sets pixels above the threshold to maxval, and others to 0", "Sets pixels below the threshold to maxval", "Inverts the image"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "The `tileGridSize` parameter in CLAHE controls the:",
    "options": ["Number of colors in the output", "Size of the tiles the image is divided into for processing", "Clip limit for contrast", "File format for saving"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "Which of these is a key takeaway about histogram equalization?",
    "options": ["It always reduces image noise", "It redistributes intensity values to enhance contrast", "It is used to change image resolution", "It converts images to JPEG format"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "Thresholding is a fundamental step in applications like OCR because it:",
    "options": ["Adds color to the text", "Isolates the text (foreground) from the background", "Increases the font size", "Translates the text to another language"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What is the first step in almost any image processing pipeline?",
    "options": ["Applying a complex neural network", "Image acquisition and preprocessing", "Deploying the model", "Writing a research paper"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What does the 'A' in CLAHE stand for?",
    "options": ["Absolute", "Adaptive", "Algorithmic", "Approximate"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Transformations & Thresholding",
    "question": "What is the purpose of the `cv2.destroyAllWindows()` function?",
    "options": ["To delete image files from disk", "To close all open OpenCV image windows", "To reset the image array to zero", "To stop all running processes"],
    "answer": 1
  },
    {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What is the core idea behind Machine Learning?",
    "options": ["Computers following a strict set of programmed rules", "Computers learning patterns from data without being explicitly programmed", "Computers only processing numerical data", "Computers replacing all human decision-making"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "Which of these is a limitation of traditional, rule-based computer vision that ML helps to solve?",
    "options": ["Handling variability in lighting conditions and object appearance", "Processing images faster than 60 frames per second", "Using less memory", "Writing simpler code"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What is the primary characteristic of Supervised Learning?",
    "options": ["It uses unlabeled data", "It finds structure or clusters in data", "It uses labeled data to learn a mapping", "It requires no training data"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "Image classification and face recognition are common examples of which type of learning?",
    "options": ["Unsupervised Learning", "Reinforcement Learning", "Semi-supervised Learning", "Supervised Learning"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "Which type of machine learning is used to find structure or clusters in unlabeled data?",
    "options": ["Supervised Learning", "Unsupervised Learning", "Deep Learning", "Transfer Learning"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What is the first step in a typical machine learning pipeline?",
    "options": ["Model Selection", "Data Collection", "Prediction", "Feature Extraction"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "Converting an image into a vector of pixel intensities or a histogram is part of which step in the ML pipeline?",
    "options": ["Data Collection", "Preprocessing", "Feature Extraction", "Model Training"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "How is the k-Nearest Neighbors (k-NN) algorithm best described?",
    "options": ["A parametric, eager learning algorithm", "A non-parametric, instance-based (lazy) learning algorithm", "A deep learning algorithm", "An ensemble learning algorithm"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "In the k-NN algorithm, what does the 'k' represent?",
    "options": ["The number of features in the data", "The number of classes to predict", "The number of nearest neighbors to consider for voting", "The kernel size"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What is the final step of the k-NN algorithm for a classification task?",
    "options": ["Building a tree structure", "The class with the most votes among the k neighbors becomes the prediction", "Calculating the entropy of the dataset", "Training a neural network"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "Which of the following is a common distance metric used in k-NN?",
    "options": ["Euclidean Distance", "Gini Impurity", "Information Gain", "Sigmoid Function"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "A major advantage of the k-NN algorithm is:",
    "options": ["It has no training time", "It is very fast for making predictions on large datasets", "It is immune to the curse of dimensionality", "It performs automatic feature scaling"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "A major limitation of the k-NN algorithm is:",
    "options": ["It is difficult to understand", "It is slow for large datasets as it computes distances to all points", "It cannot be used for classification", "It requires all data to be categorical"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What is a Decision Tree in the context of machine learning?",
    "options": ["A graph of computer hardware components", "A model that builds a tree structure where nodes ask questions about features", "A list of decisions made by a computer program", "A database for storing images"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "In a Decision Tree, what does each internal node represent?",
    "options": ["A final predicted class", "A question or test on a feature", "The accuracy of the model", "The source of the data"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What are the endpoints of a Decision Tree called?",
    "options": ["Roots", "Branches", "Leaves", "Nodes"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What is the goal when building a Decision Tree?",
    "options": ["To make the tree as wide as possible", "To recursively split the data to make it purer at each node", "To use as many features as possible in the root node", "To avoid asking any questions about the data"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "Which metrics are commonly used to find the best feature to split on in a Decision Tree?",
    "options": ["Euclidean Distance and Manhattan Distance", "Gini Impurity and Information Gain (Entropy)", "Mean and Median", "Pixel Intensity and Saturation"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "A key advantage of Decision Trees is:",
    "options": ["They are easy to interpret and visualize", "They are never prone to overfitting", "They are the most accurate model for all problems", "They do not require any data to train"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "A major limitation of Decision Trees is that they are:",
    "options": ["Too slow for making predictions", "Prone to overfitting, especially with deep trees", "Unable to handle numerical data", "Impossible to train on image data"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "Compared to k-NN, a key difference for Decision Trees is:",
    "options": ["They have a long training time but fast prediction time", "They require no training time", "They are a type of deep learning", "They cannot be used for classification"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "Which Python library is introduced in the slides for implementing k-NN and Decision Trees?",
    "options": ["OpenCV", "TensorFlow", "PyTorch", "scikit-learn"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What is the purpose of splitting data into training and testing sets?",
    "options": ["To make the dataset larger", "To train the model on one subset and evaluate its performance on unseen data from another", "To only use the testing set for training", "To delete unnecessary data"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "The 'digits' dataset mentioned in the lab activity likely refers to images of what?",
    "options": ["Animal faces", "Handwritten digits (0-9)", "Street signs", "Fruits"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "Tuning the parameter 'k' in k-NN is an example of:",
    "options": ["Data collection", "Model evaluation", "Hyperparameter tuning", "Feature extraction"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What does a high value of 'k' in k-NN typically lead to?",
    "options": ["A more complex model that may overfit", "A smoother decision boundary that is less prone to noise", "A model that only considers one neighbor", "A model that cannot make predictions"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What does a low value of 'k' in k-NN typically lead to?",
    "options": ["A very simple model", "A decision boundary that is very sensitive to noise", "No change in the model", "A model that is very slow"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "The problem where a model performs well on training data but poorly on unseen test data is called:",
    "options": ["Underfitting", "Overfitting", "Preprocessing", "Feature extraction"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "Which algorithm is described as 'lazy' because it does no work until a prediction is required?",
    "options": ["Decision Tree", "k-Nearest Neighbors (k-NN)", "Random Forest", "Support Vector Machine"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "Which algorithm builds an explicit model (a tree) during the training phase?",
    "options": ["k-Nearest Neighbors (k-NN)", "Decision Tree", "Both k-NN and Decision Trees", "Neither k-NN nor Decision Trees"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "For a dataset with many irrelevant features, which algorithm would likely perform worse without feature selection?",
    "options": ["Decision Tree", "k-Nearest Neighbors (k-NN)", "They would perform the same", "Neither can use features"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What is the purpose of normalizing or scaling features before using k-NN?",
    "options": ["To make the image colors more vibrant", "To ensure all features contribute equally to the distance calculation", "To reduce the number of features", "To convert the task to unsupervised learning"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "The 'Gini impurity' measure used in Decision Trees indicates:",
    "options": ["The distance between two data points", "The likelihood of misclassifying a randomly chosen element from the node", "The number of neighbors to consider", "The depth of the tree"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "A node in a Decision Tree is 'pure' if:",
    "options": ["It contains samples from many different classes", "All samples in the node belong to the same class", "It is the root node", "It has no children"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What does 'max depth' refer to in a Decision Tree?",
    "options": ["The number of features used", "The maximum number of times the tree can split, controlling its complexity", "The height of the computer screen used to display the tree", "The number of training samples"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "k-NN and Decision Trees are considered foundations for more advanced techniques like:",
    "options": ["Random Forests and Neural Networks", "Only other lazy learning algorithms", "Only other tree-based algorithms", "They are the most advanced techniques themselves"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "In the context of ML in vision, what does 'feature extraction' from an image often involve?",
    "options": ["Taking a photograph with a camera", "Reducing the image to a set of numerical values that describe it (e.g., flattening pixels)", "Labeling the image by hand", "Deleting the image from the dataset"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "Why might a simple algorithm like k-NN or a Decision Tree be a good starting point for an image classification problem?",
    "options": ["They are always the best-performing models", "They are complex and difficult to implement", "They are easy to implement and provide a baseline for performance", "They require no data to run"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What is the primary output of a trained classification model like k-NN or Decision Tree?",
    "options": ["A reconstructed image", "A predicted class label for a new input", "A distance matrix", "A loss function value"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "The slides mention that ML enables automation in computer vision for tasks like classification, detection, and segmentation. What is the key enabler for this?",
    "options": ["Learning from examples (data)", "Having faster processors", "Using more colorful images", "Writing longer code"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What is a common way to evaluate the performance of a classification model?",
    "options": ["Accuracy (the proportion of correct predictions)", "The height of the decision tree", "The value of k in k-NN", "The number of features extracted"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "If a Decision Tree is 'unstable', it means:",
    "options": ["It might fall over physically", "Small changes in the training data can result in a very different tree", "It cannot make predictions", "It is made of metal"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "Which step in the ML pipeline comes immediately after 'Model Selection'?",
    "options": ["Data Collection", "Preprocessing", "Training", "Prediction"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "The 'curse of dimensionality' is a particular problem for which algorithm?",
    "options": ["Decision Trees", "k-Nearest Neighbors", "Both equally", "Neither"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What is the primary reason k-NN is considered a 'non-parametric' method?",
    "options": ["It does not make strong assumptions about the form of the underlying data distribution", "It has no parameters to set", "It only works with categorical parameters", "It was invented before parameters were discovered"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "In a Decision Tree, what does the root node represent?",
    "options": ["The final decision", "The entire dataset before any splits", "A random subset of the data", "The testing data"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Intro to Machine Learning",
    "question": "What is the main goal of using machine learning for image tasks, as opposed to hand-crafted rules?",
    "options": ["To eliminate the need for data", "To automate feature discovery and improve generalization to new data", "To make algorithms simpler to code", "To reduce the need for computational power"],
    "answer": 1
  },
   {
    "section": "Computer Vision Fundamentals",
    "question": "What is the primary objective of computer vision?",
    "options": [
      "To enhance image quality through filtering and resizing",
      "To enable machines to interpret and understand visual information",
      "To develop new camera technologies for image acquisition",
      "To create augmented reality applications for entertainment"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision Fundamentals",
    "question": "Which of the following is a key objective of computer vision?",
    "options": [
      "Creating 3D models from images",
      "Recognizing patterns in images",
      "Improving image resolution",
      "Compressing image file sizes"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision Fundamentals",
    "question": "In the context of computer vision, what does 'semantic understanding' refer to?",
    "options": [
      "Scene segmentation",
      "Increasing image contrast",
      "Adjusting image brightness",
      "Identifying edges in an image"
    ],
    "answer": 0
  },
  {
    "section": "Computer Vision Applications",
    "question": "Which application of computer vision is commonly used in security systems?",
    "options": [
      "Facial recognition",
      "Medical diagnostics",
      "Autonomous navigation",
      "Industrial robotics"
    ],
    "answer": 0
  },
  {
    "section": "Computer Vision Fundamentals",
    "question": "What is the main difference between image processing and computer vision?",
    "options": [
      "Image processing uses cameras, while computer vision uses scanners",
      "Image processing enhances images, while computer vision extracts meaning from images",
      "Image processing is used in augmented reality, while computer vision is not",
      "Image processing requires more computational power than computer vision"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision Workflow",
    "question": "Which of the following is the first step in a basic computer vision workflow?",
    "options": [
      "Pre-processing",
      "Decision making",
      "Image acquisition",
      "Feature extraction"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision Workflow",
    "question": "What is the purpose of pre-processing in computer vision?",
    "options": [
      "Making decisions based on image content",
      "Classifying objects in the image",
      "Improving image quality",
      "Extracting key features"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision Workflow",
    "question": "Which of the following techniques is used in the feature extraction step of computer vision?",
    "options": [
      "Image compression",
      "Detecting edges",
      "Color correction",
      "Image resizing"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision Workflow",
    "question": "What type of output is expected from the computer vision step of understanding/interpretation?",
    "options": [
      "Resized image",
      "Grayscale image",
      "Classification",
      "Filtered image"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision Applications",
    "question": "In which application of computer vision are abnormalities in X-rays detected?",
    "options": [
      "Medical imaging",
      "Industrial automation",
      "Augmented reality",
      "Autonomous vehicles"
    ],
    "answer": 0
  },
  {
    "section": "Computer Vision Tools",
    "question": "Which Python library is specifically designed for computer vision tasks?",
    "options": [
      "NumPy",
      "Pillow",
      "OpenCV",
      "Matplotlib"
    ],
    "answer": 2
  },
  {
    "section": "Image Processing",
    "question": "What is the primary purpose of converting an image to grayscale?",
    "options": [
      "To simplify image data by removing color information",
      "To increase the number of color channels in the image",
      "To enhance the color information in the image",
      "To reduce the file size of the image"
    ],
    "answer": 0
  },
  {
    "section": "OpenCV",
    "question": "In OpenCV, what color format is an image initially loaded in?",
    "options": [
      "RGBA",
      "BGR",
      "RGB",
      "CMYK"
    ],
    "answer": 1
  },
  {
    "section": "OpenCV",
    "question": "What does the `cv2.cvtColor()` function do?",
    "options": [
      "It converts an image from one color space to another",
      "It displays an image using Matplotlib",
      "It saves an image to a file",
      "It loads an image from a file"
    ],
    "answer": 0
  },
  {
    "section": "OpenCV",
    "question": "What is the shape of a grayscale image's NumPy array in OpenCV?",
    "options": [
      "(width, height)",
      "(height, width)",
      "(width, height, color channels)",
      "(height, width, color channels)"
    ],
    "answer": 1
  },
  {
    "section": "Computer Vision Fundamentals",
    "question": "Which term describes a grid of small picture elements that make up a digital image?",
    "options": [
      "Vectors",
      "Pixels",
      "Matrices",
      "Filters"
    ],
    "answer": 1
  },
  {
    "section": "Color Models",
    "question": "Which color model is additive and combines Red, Green, and Blue light?",
    "options": [
      "CMYK",
      "HSV",
      "RGB",
      "LAB"
    ],
    "answer": 2
  },
  {
    "section": "Color Models",
    "question": "Which color model separates color information (Hue) from intensity (Value) and vividness (Saturation)?",
    "options": [
      "RGB",
      "Grayscale",
      "HSV",
      "BGR"
    ],
    "answer": 2
  },
  {
    "section": "Image Properties",
    "question": "What does an image's resolution refer to?",
    "options": [
      "The number of colors it can display",
      "The number of pixels along its width and height",
      "Its physical size when printed",
      "The sharpness of its edges"
    ],
    "answer": 1
  },
  {
    "section": "Image Properties",
    "question": "An image with a resolution of 1920x1080 is also known as:",
    "options": [
      "4K",
      "720p",
      "1080p",
      "SD"
    ],
    "answer": 2
  },
  {
    "section": "Image Representation",
    "question": "How is a color image typically represented in memory in Python with OpenCV?",
    "options": [
      "As a list of strings",
      "As a NumPy array",
      "As a dictionary of values",
      "As a Pandas DataFrame"
    ],
    "answer": 1
  },
  {
    "section": "Machine Learning",
    "question": "What is the main goal of machine learning in computer vision?",
    "options": [
      "To manually code rules for every object",
      "To learn patterns from data without explicit programming",
      "To replace all traditional image processing",
      "To only work with black and white images"
    ],
    "answer": 1
  },
  {
    "section": "Machine Learning",
    "question": "Which type of machine learning uses labeled data?",
    "options": [
      "Unsupervised Learning",
      "Supervised Learning",
      "Reinforcement Learning",
      "Semi-supervised Learning"
    ],
    "answer": 1
  },
  {
    "section": "Algorithms",
    "question": "The k-Nearest Neighbors (k-NN) algorithm is best described as:",
    "options": [
      "A parametric, eager learning algorithm",
      "A non-parametric, lazy learning algorithm",
      "A deep learning algorithm",
      "A clustering algorithm"
    ],
    "answer": 1
  },
  {
    "section": "Algorithms",
    "question": "A model that builds a tree structure where nodes ask questions about features is a:",
    "options": [
      "k-NN model",
      "Decision Tree model",
      "Neural Network",
      "Support Vector Machine"
    ],
    "answer": 1
  },
  {
    "section": "Image Transformations",
    "question": "What does geometric transformation modify in an image?",
    "options": [
      "The color values of pixels",
      "The spatial relationship of pixels",
      "The file format",
      "The compression ratio"
    ],
    "answer": 1
  },
  {
    "section": "Image Analysis",
    "question": "What does an image histogram graphically represent?",
    "options": [
      "The geographic location where the image was taken",
      "The distribution of pixel intensity values",
      "The chronological history of edits to the image",
      "The color palette used by the artist"
    ],
    "answer": 1
  },
  {
    "section": "Image Analysis",
    "question": "A narrow, concentrated histogram typically indicates an image with:",
    "options": [
      "High contrast",
      "Low contrast",
      "Many colors",
      "A high resolution"
    ],
    "answer": 1
  },
  {
    "section": "Image Enhancement",
    "question": "What is the goal of histogram equalization?",
    "options": [
      "To reduce the image's file size",
      "To convert the image to grayscale",
      "To enhance contrast by spreading out intensity values",
      "To apply a blur effect to the image"
    ],
    "answer": 2
  },
  {
    "section": "Image Enhancement",
    "question": "Which technique divides an image into tiles and applies histogram equalization separately to each one to limit noise amplification?",
    "options": [
      "Global Histogram Equalization",
      "Adaptive Thresholding",
      "CLAHE",
      "Otsu's Binarization"
    ],
    "answer": 2
  },
  {
    "section": "Segmentation",
    "question": "The process of converting a grayscale image to a black and white image is called:",
    "options": [
      "Filtering",
      "Thresholding",
      "Equalization",
      "Transformation"
    ],
    "answer": 1
  },
  {
    "section": "Segmentation",
    "question": "Which thresholding method automatically selects an optimal threshold value by minimizing intra-class variance?",
    "options": [
      "Simple Thresholding",
      "Adaptive Thresholding",
      "Otsu's Method",
      "Binary Thresholding"
    ],
    "answer": 2
  },
  {
    "section": "OpenCV",
    "question": "Which function is used to read an image from a file in OpenCV?",
    "options": [
      "cv2.read_image()",
      "cv2.load()",
      "cv2.imread()",
      "cv2.open()"
    ],
    "answer": 2
  },
  {
    "section": "OpenCV",
    "question": "Which function is used to display an image in an OpenCV window?",
    "options": [
      "cv2.display()",
      "cv2.show()",
      "cv2.imshow()",
      "cv2.preview()"
    ],
    "answer": 2
  },
  {
    "section": "OpenCV",
    "question": "What does the `cv2.waitKey(0)` function do?",
    "options": [
      "Saves the image with quality 0",
      "Waits indefinitely for a keyboard event",
      "Closes all windows after 0 milliseconds",
      "Sets the window title"
    ],
    "answer": 1
  },
  {
    "section": "OpenCV",
    "question": "Which function is used to split a BGR image into its individual color channels?",
    "options": [
      "cv2.divide()",
      "cv2.separate()",
      "cv2.split()",
      "cv2.channels()"
    ],
    "answer": 2
  },
  {
    "section": "OpenCV",
    "question": "Which function is used to save a processed image to a file?",
    "options": [
      "cv2.write()",
      "cv2.save()",
      "cv2.export()",
      "cv2.imwrite()"
    ],
    "answer": 3
  },
  {
    "section": "Data",
    "question": "What is the purpose of splitting data into training and testing sets?",
    "options": [
      "To increase the total amount of data",
      "To evaluate the model's performance on unseen data",
      "To make the training process faster",
      "To reduce the memory usage"
    ],
    "answer": 1
  },
  {
    "section": "Evaluation",
    "question": "What is a common metric for evaluating a classification model?",
    "options": [
      "Pixel Intensity",
      "Resolution",
      "Accuracy",
      "Contrast Ratio"
    ],
    "answer": 2
  },
  {
    "section": "Challenges",
    "question": "A model that performs well on training data but poorly on new, unseen data is likely:",
    "options": [
      "Underfitting",
      "Overfitting",
      "Well-balanced",
      "Too simple"
    ],
    "answer": 1
  },
  {
    "section": "Applications",
    "question": "Which computer vision application is essential for self-driving cars?",
    "options": [
      "Medical image analysis",
      "Facial recognition",
      "Autonomous navigation",
      "Document scanning"
    ],
    "answer": 2
  },
  {
    "section": "Applications",
    "question": "Optical Character Recognition (OCR) is used to:",
    "options": [
      "Recognize faces in images",
      "Detect edges in a scene",
      "Identify and extract text from images",
      "Compress image files"
    ],
    "answer": 2
  },
  {
    "section": "History",
    "question": "The field of computer vision started to develop significantly with the advent of:",
    "options": [
      "The printing press",
      "The digital computer",
      "The television",
      "The smartphone"
    ],
    "answer": 1
  },
  {
    "section": "Future Trends",
    "question": "Which advanced technology is pushing the current boundaries of computer vision?",
    "options": [
      "Deep Learning and Convolutional Neural Networks (CNNs)",
      "Larger image sensors",
      "Higher resolution displays",
      "Faster internet connections"
    ],
    "answer": 0
  },
  {
    "section": "Ethics",
    "question": "A major ethical concern in computer vision is:",
    "options": [
      "The high cost of cameras",
      "The complexity of algorithms",
      "Privacy and surveillance",
      "The speed of processing"
    ],
    "answer": 2
  },
  {
    "section": "Hardware",
    "question": "Which hardware component is most critical for capturing images for computer vision?",
    "options": [
      "GPU",
      "CPU",
      "Image Sensor",
      "Hard Drive"
    ],
    "answer": 2
  },
  {
    "section": "Libraries",
    "question": "Which library is commonly used alongside OpenCV for plotting graphs and histograms?",
    "options": [
      "TensorFlow",
      "PyTorch",
      "Matplotlib",
      "Scikit-learn"
    ],
    "answer": 2
  },
  {
    "section": "Computer Vision - Color Models",
    "question": "What does the 'Value' component represent in the HSV color model?",
    "options": ["Type of color", "Green-Red component", "Brightness", "Color purity"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Representation",
    "question": "In digital image representation, what do the variables x and y represent in the function f(x, y)?",
    "options": ["Spatial coordinates", "Color intensity", "Grayscale value", "Image resolution"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Color Models",
    "question": "Which color model is most suitable for color filtering or detection tasks?",
    "options": ["RGB", "Grayscale", "CMYK", "HSV"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Color Models",
    "question": "What is the primary use of the CMYK color model?",
    "options": ["Image simplification", "Video compression", "Display screens", "Printing"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Image Resolution",
    "question": "What is the significance of image resolution in the context of digital images?",
    "options": ["It determines the image's aspect ratio", "It defines the color channels in the image", "It indicates the number of pixels in the image", "It represents the proportion of width to height"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Grayscale Conversion",
    "question": "How is a grayscale image typically derived from an RGB image?",
    "options": ["By discarding the color information entirely", "By selecting the maximum value among red, green, and blue", "By using a weighted sum of the RGB values", "By taking the average of the red, green, and blue values"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Properties",
    "question": "What does image bit depth define?",
    "options": ["The number of possible values a pixel can take", "The number of channels in the image", "The compression level of the image", "The resolution of the image"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Color Models",
    "question": "Which color model is often better than RGB for skin detection tasks?",
    "options": ["Grayscale", "Blue, Green, Red", "EXIF", "HSV/YCrCb"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Image Storage",
    "question": "How is an image typically stored in Python/OpenCV?",
    "options": ["A dictionary of colors", "A list of pixels", "A string of characters", "A NumPy array"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Image Storage",
    "question": "What is the shape of a 512x512 RGB image stored as a NumPy array?",
    "options": ["(512, 512, 3)", "(3, 512, 512)", "(512, 512, 1)", "(512, 3, 512)"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Color Models",
    "question": "Which color model separates color information into hue, saturation, and value components?",
    "options": ["HSV", "RGB", "Grayscale", "LAB"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Grayscale Images",
    "question": "What type of data does a grayscale image primarily represent?",
    "options": ["Saturation", "Color information", "Intensity", "Hue"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Color Models",
    "question": "Which color model is based on human perception of color?",
    "options": ["LAB", "HSV", "RGB", "Grayscale"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Image Analysis",
    "question": "What does a histogram of a grayscale image represent?",
    "options": ["The saturation levels in the image", "The spatial arrangement of objects", "The distribution of pixel intensities", "The color composition of the image"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Extra",
    "question": "Which OpenCV function is commonly used to convert an RGB image to grayscale?",
    "options": ["cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)", "cv2.threshold()", "cv2.filter2D()", "cv2.equalizeHist()"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Geometric Transformations",
    "question": "What is the primary purpose of geometric transformations in image processing?",
    "options": ["To remove noise from an image", "To adjust the color balance of an image", "To modify the spatial relationship of pixels in an image", "To compress the image file size"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Scaling",
    "question": "In the context of image scaling, what does a scale factor 's < 1' indicate?",
    "options": ["The image rotates", "The image is sheared", "The image enlarges", "The image shrinks"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Transformations",
    "question": "Which of the following transformations is considered an affine transformation?",
    "options": ["Histogram equalization", "Edge detection", "Translation", "Thresholding"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Histograms",
    "question": "What information does an image histogram provide?",
    "options": ["Compression rate of the image", "Camera settings used to capture the image", "Distribution of pixel intensity values", "Spatial arrangement of objects"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Histograms",
    "question": "What effect does a narrow, concentrated histogram typically indicate about an image?",
    "options": ["Low contrast", "Excessive noise", "Balanced color distribution", "High contrast"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Image Histograms",
    "question": "What does a narrow grayscale histogram typically indicate about an image?",
    "options": ["Evenly distributed pixel intensities", "High contrast", "Low contrast", "Image is mostly bright"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Histograms",
    "question": "In the context of image histograms, what does a 'skewed right' distribution generally suggest?",
    "options": ["The image is mostly dark", "The image has low contrast", "The image is mostly bright", "Pixel intensities are evenly distributed"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Histograms",
    "question": "What is the purpose of calculating separate histograms for each color channel (Red, Green, Blue) in a color image?",
    "options": ["To analyze color distribution and channel dominance", "To enhance image sharpness", "To reduce the image size", "To convert the image to grayscale"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Image Histograms",
    "question": "Which of the following is NOT a typical application of histograms in computer vision?",
    "options": ["Contrast enhancement", "Thresholding", "Edge detection", "Segmentation"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Histogram Equalization",
    "question": "What is the primary purpose of histogram equalization?",
    "options": ["To identify the objects present in an image", "To reduce the file size of an image", "To blur the image for aesthetic purposes", "To improve contrast in an image"],
    "answer": 3
  },
  {
    "section": "Computer Vision - OpenCV Basics",
    "question": "In OpenCV, what is the color order in which images are loaded by default?",
    "options": ["HSV", "BGR", "CMYK", "RGB"],
    "answer": 1
  },
  {
    "section": "Computer Vision - OpenCV Functions",
    "question": "What is the purpose of the `cv2.calcHist()` function?",
    "options": ["To apply a blur effect to an image", "To equalize the histogram of an image", "To compute the histogram for an image channel", "To convert an image to grayscale"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Histogram Equalization",
    "question": "What is a potential problem with global histogram equalization that CLAHE aims to solve?",
    "options": ["Increased computational complexity", "Inability to process color images", "Excessive reduction of contrast", "Over-amplification of noise in some regions"],
    "answer": 3
  },
  {
    "section": "Computer Vision - CLAHE",
    "question": "What is the primary purpose of Contrast Limited Adaptive Histogram Equalization (CLAHE)?",
    "options": ["To apply a fixed threshold globally across the image", "To enhance local contrast while limiting noise amplification", "To convert a grayscale image into a color image", "To reduce the file size of an image"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Histogram Equalization",
    "question": "Under what lighting conditions is standard histogram equalization least suitable?",
    "options": ["Low-contrast grayscale image", "Image with natural lighting", "Medical images", "Industrial images"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Thresholding",
    "question": "What is the main limitation of simple thresholding?",
    "options": ["It requires manual adjustment of parameters", "It doesn’t handle varying lighting well", "It cannot be applied to color images", "It is computationally expensive"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Thresholding",
    "question": "Which of the following is NOT a typical application of thresholding in computer vision?",
    "options": ["Geometric transforms", "OCR", "Motion detection", "Segmentation"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Thresholding",
    "question": "What does Otsu's Binarization method analyze to select the optimal threshold?",
    "options": ["Image resolution", "Color distribution", "Image histogram", "Spatial frequency"],
    "answer": 2
  },
   {
    "section": "Computer Vision - Image Filtering",
    "question": "What is the primary purpose of image filtering in computer vision?",
    "options": ["To reduce the file size of an image", "To increase the resolution of an image", "To convert an image to a different color space", "To modify an image to enhance certain features or suppress others"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Image Filtering",
    "question": "Which type of kernel is used to smooth an image by averaging the pixel values?",
    "options": ["Sharpening", "Sobel", "Box Blur", "Identity"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Filtering",
    "question": "What is the mathematical operation used in image filtering to apply a kernel to an image?",
    "options": ["Deconvolution", "Integration", "Convolution", "Differentiation"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Filtering",
    "question": "Which type of kernel leaves the image unchanged?",
    "options": ["Box Blur", "Gaussian Blur", "Identity", "Sobel"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "What is the purpose of Sobel kernels in image filtering?",
    "options": ["Edge detection", "Smoothing", "Sharpening", "Color enhancement"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Image Filtering",
    "question": "What is the primary purpose of smoothing (or blurring) in image preprocessing?",
    "options": ["To sharpen edges and increase contrast", "To detect motion and track objects", "To reduce high-frequency noise and enhance structural features", "To segment images into distinct regions"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Image Filtering",
    "question": "Which type of filter is most effective at preserving edges while removing noise?",
    "options": ["Non-linear filter", "Sobel filter", "Box filter", "Gaussian filter"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Image Filtering",
    "question": "What is the main mathematical operation used in image filtering?",
    "options": ["Integration", "Normalization", "Differentiation", "Convolution"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Image Filtering",
    "question": "In the context of image filtering, what does the standard deviation (σ) control in a Gaussian kernel?",
    "options": ["The symmetry of the image", "The speed of the blur", "The direction of edge detection", "The intensity of color enhancement"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Image Filtering",
    "question": "Why is filtering considered an important initial step in many computer vision workflows?",
    "options": ["It reduces noise and enhances features before applying advanced algorithms", "It increases the computational complexity of subsequent steps", "It automatically identifies and labels objects in the image", "It converts images to grayscale"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "What does an edge in an image primarily represent?",
    "options": ["A point of average pixel intensity", "A region of gradual color change", "A boundary between distinct regions", "A uniform area of constant intensity"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "Which of the following is NOT a typical characteristic of edges in images?",
    "options": ["Object outlines", "Uniform intensity", "Surface discontinuities", "Shadows and reflections"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "In the mathematical definition of an edge, what does the magnitude of the gradient (∇I) represent?",
    "options": ["The direction of the edge", "The rate of color change", "The strength of the edge", "The average intensity of the image"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "Which type of edge is characterized by a gradual change in intensity?",
    "options": ["Line Edge", "Ramp Edge", "Step Edge", "Roof Edge"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "Which edge detection technique uses the second derivative and is highly sensitive to noise?",
    "options": ["Prewitt", "Laplacian", "Sobel", "Canny"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "What is the purpose of the 'Non-maximum Suppression' step in the Canny edge detection pipeline?",
    "options": ["To compute gradients", "To reduce noise", "To smooth the image", "To thin the edges"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "What does visualizing the 'Sobel X' gradient map primarily highlight in an image?",
    "options": ["Diagonal edges", "Vertical edges", "Curved edges", "Horizontal edges"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "Which characteristic is NOT a desired attribute of a good edge detector?",
    "options": ["High sensitivity to noise", "Good selectivity (avoiding false positives)", "Good localization of edges", "Good detection of true edges"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "What is the primary function of the Sobel operator?",
    "options": ["To compress an image file size", "To apply Gaussian blur to an image", "To approximate the first derivative of image intensity, highlighting edges", "To enhance the color saturation of an image"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "What type of filter is the Sobel operator?",
    "options": ["Linear filter", "Median filter", "Non-linear filter", "Bilateral filter"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "What is the typical kernel size used in the Sobel operator?",
    "options": ["3x3", "5x5", "7x7", "1x1"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "What does the Sobel X operator primarily highlight in an image?",
    "options": ["Curved edges", "Vertical edges", "Horizontal edges", "Diagonal edges"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "What does the gradient magnitude computed from Sobel X and Y filters represent?",
    "options": ["Texture of the edge", "Color of the edge", "Direction of the edge", "Strength of the edge"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "Why is the Sobel operator preferred over a simple derivative for edge detection?",
    "options": ["It incorporates smoothing to reduce noise sensitivity", "It directly calculates the second derivative", "It only detects horizontal edges", "It increases noise sensitivity for better edge detection"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "In what scenario is the Sobel operator most suitable?",
    "options": ["Real-time applications where speed and simplicity are important", "Detecting edges in images with very low contrast", "Applications requiring extremely high precision and detail", "Applications needing rotation-invariant edge detection"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "What is a primary limitation of the Sobel operator?",
    "options": ["It is insensitive to weak edges", "It cannot detect diagonal edges", "It is sensitive to noise", "It is computationally expensive"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Canny Edge Detection",
    "question": "What is the first step in the Canny edge detection pipeline?",
    "options": ["Noise reduction using a Gaussian blur", "Edge validation", "Edge thinning", "Thresholding"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Canny Edge Detection",
    "question": "What is the main goal of 'Good Localization' in the context of Canny edge detection?",
    "options": ["Maximizing the response to a single edge", "Minimizing the number of detected edges", "Ensuring edges are detected regardless of their orientation", "Ensuring detected edges are as close as possible to the true edge"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Canny Edge Detection",
    "question": "What is the purpose of Non-Maximum Suppression in the Canny edge detection algorithm?",
    "options": ["To compute the gradient magnitude and direction", "To apply a Gaussian blur to the image", "To classify edge pixels into strong, weak, and non-edges", "To thin the edges and retain sharp outlines"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Canny Edge Detection",
    "question": "In the Canny edge detection algorithm, what is the role of the double thresholding step?",
    "options": ["To classify edge pixels into strong edges, weak edges and non-edges", "To compute the gradient magnitude and direction of the image", "To thin the edges by removing non-maximum pixels", "To connect weak edges to strong edges to create continuous lines"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Canny Edge Detection",
    "question": "What is the purpose of applying Sobel filters in the X and Y directions during the Canny edge detection process?",
    "options": ["To reduce noise in the image", "To find the intensity gradients", "To thin the edges of the image", "To connect strong and weak edges"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Canny Edge Detection",
    "question": "What is the role of 'Edge Tracking by Hysteresis' in the Canny edge detection algorithm?",
    "options": ["To create continuous, connected edges without noise", "To compute gradient magnitudes and directions", "To blur the image and reduce noise", "To classify pixels into strong, weak, and non-edges"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Canny Edge Detection",
    "question": "According to the text, what is one of the limitations of the Canny edge detector?",
    "options": ["It is sensitive to thresholds and needs careful tuning per image", "It is not applicable to medical imaging", "It is not useful for lane detection", "It cannot detect edges in grayscale images"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Edge Detection",
    "question": "Which of the following is a limitation of edge detection methods that only detect intensity edges?",
    "options": ["They perform well in uniformly lit areas", "They are unaffected by low contrast", "They may miss texture-based features", "They always produce sharp, connected edge maps"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Canny Edge Detection",
    "question": "What is a key advantage of the Canny edge detector compared to simpler gradient methods like Sobel?",
    "options": ["It is less accurate", "It provides better clarity and precision", "It is less computationally expensive", "It is more sensitive to noise"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Canny Edge Detection",
    "question": "Which of the following best describes the Canny edge detection algorithm?",
    "options": ["An algorithm that relies solely on texture-based features", "A multi-step algorithm producing sharp, connected, and noise-reduced edge maps", "A single-step process for detecting edges", "An algorithm designed only for grayscale images"],
    "answer": 1
  },
   {
    "section": "Computer Vision - Template Matching",
    "question": "What is the primary purpose of template matching?",
    "options": ["To enhance the contrast of an image", "To blur an image for noise reduction", "To compress an image file size", "To find parts of an image that match a given template image"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Template Matching",
    "question": "Which of the following OpenCV methods is based on correlation?",
    "options": ["cv2.TM_CCOEFF", "cv2.minMaxLoc", "cv2.TM_SQDIFF", "cv2.TM_CCORR_NORMED"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Template Matching",
    "question": "For which template matching method are lower values indicative of a better match?",
    "options": ["Squared difference", "Normalized cross-correlation", "Correlation coefficient", "Cross-correlation"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Template Matching",
    "question": "What does the `cv2.minMaxLoc` function return in the context of template matching?",
    "options": ["Minimum value, maximum value, minimum location, and maximum location", "The average color of the matched region", "The dimensions of the template image", "The rotation angle of the matched object"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Template Matching",
    "question": "Which of the following is a limitation of template matching?",
    "options": ["It is not scale-invariant", "It is not sensitive to occlusion", "It requires high computational power regardless of image size", "It works effectively with rotated objects"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Contours",
    "question": "What is a contour in image processing?",
    "options": ["A collection of disconnected pixels in an image", "A curve that joins all continuous points along a boundary with the same color or intensity", "A 3D representation of an object's surface", "A random selection of pixels in an image"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Contours",
    "question": "In the context of contour detection, what is the purpose of smoothing an image?",
    "options": ["To sharpen the edges in the image", "To increase the image resolution", "To reduce noise", "To enhance the color of the image"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Contours",
    "question": "Which type of image is typically used as input for contour detection algorithms?",
    "options": ["Color images", "High-resolution images", "Binary images", "Raw images"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Contours",
    "question": "What is a primary application of contour detection?",
    "options": ["Image compression", "Noise removal", "Color correction", "Shape analysis"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Contours",
    "question": "What is the purpose of the `cv2.THRESH_BINARY` flag in the `cv2.threshold` function?",
    "options": ["It converts the image to grayscale", "It blurs the image to reduce noise", "It detects edges in the image", "It applies binary thresholding to the grayscale image, setting pixel values to either black or white based on a threshold"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Contours",
    "question": "What does the `cv2.RETR_EXTERNAL` flag do in the `cv2.findContours` function?",
    "options": ["It retrieves all contours, including those inside others", "It retrieves only vertical contours", "It retrieves only horizontal contours", "It retrieves only the outermost contours"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Contours",
    "question": "What is the purpose of the `cv2.CHAIN_APPROX_SIMPLE` method in the `cv2.findContours` function?",
    "options": ["It approximates contours with a polygon", "It compresses contour points to save memory by storing only the endpoints of straight lines", "It removes noise from the contour", "It stores all points along the contour"],
    "answer": 1
  },
  {
    "section": "Computer Vision - Contours",
    "question": "In the `cv2.drawContours` function, what does the `-1` argument signify when specifying which contours to draw?",
    "options": ["Draw no contours", "Draw only the last contour", "Draw all contours", "Draw only the first contour"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Contours",
    "question": "What contour retrieval mode retrieves only the outermost contours?",
    "options": ["RETR_EXTERNAL", "RETR_TREE", "CHAIN_APPROX_NONE", "RETR_LIST"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Contours",
    "question": "Which contour approximation method compresses horizontal, vertical, and diagonal segments?",
    "options": ["CHAIN_APPROX_NONE", "RETR_EXTERNAL", "CHAIN_APPROX_SIMPLE", "RETR_TREE"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Contours",
    "question": "After extracting contours, which function calculates the area of a contour?",
    "options": ["cv2.approxPolyDP(cnt, epsilon, True)", "cv2.arcLength(cnt, True)", "cv2.boundingRect(cnt)", "cv2.contourArea(cnt)"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Contours",
    "question": "What does the `cv2.arcLength()` function compute when applied to a contour?",
    "options": ["A rectangle bounding the contour", "The center coordinates of the contour", "The area enclosed by the contour", "The perimeter of the contour"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Contours",
    "question": "What is the primary function of contour approximation using `cv2.approxPolyDP`?",
    "options": ["To change the color of a contour", "To blur the contour for better visualization", "To increase the number of points in a contour", "To simplify a contour by reducing the number of points"],
    "answer": 3
  },
  {
    "section": "Computer Vision - Contours",
    "question": "Which of the following is a real-world application of contour analysis?",
    "options": ["Coin counting", "Predicting stock prices", "Designing websites", "Writing poetry"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Contours",
    "question": "What preprocessing steps are crucial for good contour detection results?",
    "options": ["Compression, encryption, and watermarking", "Edge enhancement, color balancing, and sharpening", "Grayscale conversion, blurring, and thresholding", "Rotation, scaling, and translation"],
    "answer": 2
  },
  {
    "section": "Computer Vision - Contours",
    "question": "What is a limitation of contour detection related to image quality?",
    "options": ["Poor thresholding gives poor contours", "It only works on color images", "It requires high resolution images", "It is not affected by image quality"],
    "answer": 0
  },
  {
    "section": "Computer Vision - Contours",
    "question": "What does OpenCV provide for contour analysis?",
    "options": ["Algorithms for text recognition", "Tools for 3D modeling", "Easy tools to detect, draw, and analyze contours", "Functions for audio processing"],
    "answer": 2
  },
  
]